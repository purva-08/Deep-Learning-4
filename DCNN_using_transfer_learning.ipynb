{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Import libraries**"
      ],
      "metadata": {
        "id": "hGwXI__bx5JA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keras imports for the dataset and building our neural network\n",
        "import keras \n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten,Input,BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "aPQfAGj9x842"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section I: Used datasets**"
      ],
      "metadata": {
        "id": "M0_Ro0c_yUeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load and preprocess the CIFAR10 dataset**"
      ],
      "metadata": {
        "id": "_GgKr3KNy0A-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8GATXoKyxZb",
        "outputId": "253a0435-9c10-43c0-d43e-ffde4b81aa6d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training data shape : ', X_train.shape, y_train.shape)\n",
        "\n",
        "print('Testing data shape : ', X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRmGBTH3y4RW",
        "outputId": "572eb167-c40d-40ff-9ff9-6c2e938e56df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape :  (50000, 32, 32, 3) (50000, 1)\n",
            "Testing data shape :  (10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make a input vector so we \n",
        "#reshape it into input format for training and testing sets. After that change all datatypes into floats\n",
        "\n",
        "# building the input vector from the 32x32 pixels\n",
        "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
        "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "metadata": {
        "id": "rHgtRsXwy6gj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizing the data to help with the training\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "metadata": {
        "id": "yfiKq6kjy9ef"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding using keras' numpy-related utilities\n",
        "n_classes = 10\n",
        "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
        "y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "print(\"Shape after one-hot encoding: \", y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzCDWMxsy_7R",
        "outputId": "cd640700-b79b-4e45-dae8-8bf5eaf47fcf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before one-hot encoding:  (50000, 1)\n",
            "Shape after one-hot encoding:  (50000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj6T4VLszCKg",
        "outputId": "a45ffffc-f121-4468-c61c-a7eff532ec40"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section II:**"
      ],
      "metadata": {
        "id": "efMGxbx54f0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VGG16 Model work**"
      ],
      "metadata": {
        "id": "Rc3Wv82YzF_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "base_model = VGG16(input_shape =(32,32,3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1OqlMX60Wsu",
        "outputId": "a44810fa-4360-4010-f9d7-f5c646a3e09c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "wEMWgKlL0u4r"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(base_model.output)\n",
        "\n",
        "# Adding a Dense layer with 256 neurons\n",
        "x = Dense(256, activation = 'relu')(x)\n",
        "\n",
        "# Add a DropOut layer with Drop out ratio of 20%\n",
        "x =Dropout(0.2)(x)\n",
        "\n",
        "# Add a Batch Normalization layer\n",
        "x = BatchNormalization(axis=-1)(x)\n",
        "\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "# Add a DropOut layer with Drop out ratio of 20%\n",
        "x =Dropout(0.2)(x)\n",
        "\n",
        "# Add a final softmax layer for classification output\n",
        "x = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model=Model(base_model.input, x)\n",
        "\n",
        "model.compile(optimizer =Adam(learning_rate=0.001), loss ='categorical_crossentropy',metrics = ['acc'])"
      ],
      "metadata": {
        "id": "q-BSkEig0xvP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train, y_train, \n",
        "                  batch_size=64, \n",
        "                  epochs=40, \n",
        "                  validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2o-2B9l19UY",
        "outputId": "fd8e22ba-37fe-4f14-b613-cfee0d521f2d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "782/782 [==============================] - 23s 16ms/step - loss: 1.4454 - acc: 0.4924 - val_loss: 1.2732 - val_acc: 0.5470\n",
            "Epoch 2/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.2632 - acc: 0.5564 - val_loss: 1.2316 - val_acc: 0.5646\n",
            "Epoch 3/40\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 1.2068 - acc: 0.5761 - val_loss: 1.2227 - val_acc: 0.5765\n",
            "Epoch 4/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.1757 - acc: 0.5890 - val_loss: 1.1600 - val_acc: 0.5923\n",
            "Epoch 5/40\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 1.1416 - acc: 0.5978 - val_loss: 1.1554 - val_acc: 0.5959\n",
            "Epoch 6/40\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 1.1213 - acc: 0.6071 - val_loss: 1.1543 - val_acc: 0.5952\n",
            "Epoch 7/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.1106 - acc: 0.6115 - val_loss: 1.1525 - val_acc: 0.5993\n",
            "Epoch 8/40\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 1.0885 - acc: 0.6172 - val_loss: 1.1494 - val_acc: 0.6036\n",
            "Epoch 9/40\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 1.0768 - acc: 0.6207 - val_loss: 1.1355 - val_acc: 0.6062\n",
            "Epoch 10/40\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 1.0582 - acc: 0.6283 - val_loss: 1.1283 - val_acc: 0.6083\n",
            "Epoch 11/40\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 1.0428 - acc: 0.6337 - val_loss: 1.1276 - val_acc: 0.6081\n",
            "Epoch 12/40\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 1.0343 - acc: 0.6355 - val_loss: 1.1328 - val_acc: 0.6069\n",
            "Epoch 13/40\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 1.0211 - acc: 0.6387 - val_loss: 1.1401 - val_acc: 0.6088\n",
            "Epoch 14/40\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 1.0095 - acc: 0.6427 - val_loss: 1.1319 - val_acc: 0.6033\n",
            "Epoch 15/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.0065 - acc: 0.6449 - val_loss: 1.1145 - val_acc: 0.6164\n",
            "Epoch 16/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.9839 - acc: 0.6507 - val_loss: 1.1373 - val_acc: 0.6077\n",
            "Epoch 17/40\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.9818 - acc: 0.6523 - val_loss: 1.1409 - val_acc: 0.6117\n",
            "Epoch 18/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.9703 - acc: 0.6563 - val_loss: 1.1231 - val_acc: 0.6140\n",
            "Epoch 19/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.9594 - acc: 0.6588 - val_loss: 1.1232 - val_acc: 0.6138\n",
            "Epoch 20/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.9491 - acc: 0.6631 - val_loss: 1.1403 - val_acc: 0.6151\n",
            "Epoch 21/40\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.9486 - acc: 0.6641 - val_loss: 1.1299 - val_acc: 0.6186\n",
            "Epoch 22/40\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.9385 - acc: 0.6659 - val_loss: 1.1326 - val_acc: 0.6118\n",
            "Epoch 23/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.9329 - acc: 0.6675 - val_loss: 1.1382 - val_acc: 0.6126\n",
            "Epoch 24/40\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.9155 - acc: 0.6765 - val_loss: 1.1363 - val_acc: 0.6210\n",
            "Epoch 25/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.9076 - acc: 0.6761 - val_loss: 1.1351 - val_acc: 0.6116\n",
            "Epoch 26/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.9032 - acc: 0.6785 - val_loss: 1.1544 - val_acc: 0.6100\n",
            "Epoch 27/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.8973 - acc: 0.6803 - val_loss: 1.1451 - val_acc: 0.6153\n",
            "Epoch 28/40\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.8882 - acc: 0.6829 - val_loss: 1.1281 - val_acc: 0.6149\n",
            "Epoch 29/40\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.8842 - acc: 0.6845 - val_loss: 1.1688 - val_acc: 0.6137\n",
            "Epoch 30/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.8824 - acc: 0.6851 - val_loss: 1.1312 - val_acc: 0.6167\n",
            "Epoch 31/40\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.8664 - acc: 0.6901 - val_loss: 1.1393 - val_acc: 0.6168\n",
            "Epoch 32/40\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.8494 - acc: 0.6973 - val_loss: 1.1642 - val_acc: 0.6109\n",
            "Epoch 33/40\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.8474 - acc: 0.6967 - val_loss: 1.1323 - val_acc: 0.6249\n",
            "Epoch 34/40\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.8479 - acc: 0.6944 - val_loss: 1.1310 - val_acc: 0.6236\n",
            "Epoch 35/40\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.8407 - acc: 0.6990 - val_loss: 1.1601 - val_acc: 0.6131\n",
            "Epoch 36/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.8303 - acc: 0.7045 - val_loss: 1.1243 - val_acc: 0.6220\n",
            "Epoch 37/40\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.8176 - acc: 0.7064 - val_loss: 1.1393 - val_acc: 0.6177\n",
            "Epoch 38/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.8141 - acc: 0.7093 - val_loss: 1.1693 - val_acc: 0.6188\n",
            "Epoch 39/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.8103 - acc: 0.7095 - val_loss: 1.1570 - val_acc: 0.6182\n",
            "Epoch 40/40\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.8108 - acc: 0.7107 - val_loss: 1.1482 - val_acc: 0.6197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# record the training and validation accuracy and loss after each epoch\n",
        "train_acc = history.history['acc']\n",
        "train_loss = history.history['loss']\n",
        "val_acc = history.history['val_acc']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# save the training log in a file\n",
        "with open('Model_report.txt', 'w') as f:\n",
        "    for i in range(len(train_acc)):\n",
        "        f.write(\"Epoch {}: train_acc = {}, train_loss = {}, val_acc = {}, val_loss = {}\\n\".format(\n",
        "            i+1, train_acc[i], train_loss[i], val_acc[i], val_loss[i]))"
      ],
      "metadata": {
        "id": "oWK0sMsrRE4b"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section III:**"
      ],
      "metadata": {
        "id": "h0id2-B94oTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "def extract_deep_features(x):\n",
        "  # x = preprocess_input(x)\n",
        "  features = model.predict(x)\n",
        "  features = np.reshape(features, (features.shape[0], -1))\n",
        "  return features\n",
        "\n",
        "x_train_features = extract_deep_features(X_train)\n",
        "x_test_features = extract_deep_features(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPU7Am7v4nmX",
        "outputId": "3d0a99c7-1799-47ae-8909-a6163de5ec8a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 12s 7ms/step\n",
            "313/313 [==============================] - 2s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz9JY4TaCPAU",
        "outputId": "9c721c62-49ff-4694-8f65-0c1727958902"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOghVwd1Cqxa",
        "outputId": "189e50f3-608c-4837-f354-a61bfbd44b7d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert one-hot encoded labels back to integer labels\n",
        "y_train_int = np.argmax(y_train, axis=1)\n",
        "y_test_int = np.argmax(y_test, axis=1)"
      ],
      "metadata": {
        "id": "cr_uxPDsALY8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training SVM**"
      ],
      "metadata": {
        "id": "uSt2jnEUZXEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##     Training SVM model on the extracted Features \n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC(kernel='linear')\n",
        "clf.fit(x_train_features, y_train_int)\n",
        "\n",
        "score = clf.score(x_test_features, y_test_int)\n",
        "print('Test accuracy:', score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YCLbcrv5KW0",
        "outputId": "0894c3b1-ba39-4059-95a3-cd80c9f7e4d4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.6197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = clf.score(x_train_features, y_train_int)\n",
        "print('Test accuracy:', score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_6HSEPvFSLS",
        "outputId": "df78a8b9-59c7-4b92-dc32-505f3af901bd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.79872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train custom model using the deep features**"
      ],
      "metadata": {
        "id": "tYYEmj81ZMev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input shape\n",
        "input_shape = (x_train_features.shape[1],)\n",
        "\n",
        "# Define the input layer\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "# Define the first fully connected layer\n",
        "fc1 = Dense(units=256, activation='relu', name='fc1')(inputs)\n",
        "\n",
        "# Add a dropout layer to prevent overfitting\n",
        "dropout1 = Dropout(rate=0.4, name='dropout1')(fc1)\n",
        "\n",
        "# Define the second fully connected layer\n",
        "fc2 = Dense(units=128, activation='relu', name='fc2')(dropout1)\n",
        "\n",
        "# Add a dropout layer to prevent overfitting\n",
        "dropout2 = Dropout(rate=0.3, name='dropout2')(fc2)\n",
        "\n",
        "# Define the output layer\n",
        "outputs = Dense(units=10, activation='softmax', name='output')(dropout2)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=inputs, outputs=outputs, name='my_custom_model')\n",
        "\n",
        "# Compile the model with categorical cross-entropy loss and accuracy metric\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "# Train the model on the extracted features\n",
        "history = model.fit(x_train_features, y_train, batch_size=64, epochs=30, validation_data=(x_test_features, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMSrnmX-YaJx",
        "outputId": "a79b9c66-ebb9-4da6-8282-7ffc30c2d5b1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "782/782 [==============================] - 4s 4ms/step - loss: 0.7442 - accuracy: 0.7801 - val_loss: 1.3434 - val_accuracy: 0.6195\n",
            "Epoch 2/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.6421 - accuracy: 0.7947 - val_loss: 1.3328 - val_accuracy: 0.6190\n",
            "Epoch 3/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.6273 - accuracy: 0.7956 - val_loss: 1.3319 - val_accuracy: 0.6186\n",
            "Epoch 4/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.6159 - accuracy: 0.7957 - val_loss: 1.3104 - val_accuracy: 0.6179\n",
            "Epoch 5/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.6080 - accuracy: 0.7951 - val_loss: 1.3124 - val_accuracy: 0.6180\n",
            "Epoch 6/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.6030 - accuracy: 0.7947 - val_loss: 1.3456 - val_accuracy: 0.6178\n",
            "Epoch 7/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.5995 - accuracy: 0.7954 - val_loss: 1.3492 - val_accuracy: 0.6190\n",
            "Epoch 8/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5949 - accuracy: 0.7962 - val_loss: 1.3538 - val_accuracy: 0.6190\n",
            "Epoch 9/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5940 - accuracy: 0.7960 - val_loss: 1.3170 - val_accuracy: 0.6181\n",
            "Epoch 10/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5922 - accuracy: 0.7954 - val_loss: 1.3422 - val_accuracy: 0.6177\n",
            "Epoch 11/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.5890 - accuracy: 0.7960 - val_loss: 1.3490 - val_accuracy: 0.6186\n",
            "Epoch 12/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5889 - accuracy: 0.7968 - val_loss: 1.3695 - val_accuracy: 0.6179\n",
            "Epoch 13/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5877 - accuracy: 0.7968 - val_loss: 1.3555 - val_accuracy: 0.6161\n",
            "Epoch 14/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5861 - accuracy: 0.7964 - val_loss: 1.3709 - val_accuracy: 0.6195\n",
            "Epoch 15/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5865 - accuracy: 0.7961 - val_loss: 1.3863 - val_accuracy: 0.6197\n",
            "Epoch 16/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5846 - accuracy: 0.7971 - val_loss: 1.3515 - val_accuracy: 0.6178\n",
            "Epoch 17/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5813 - accuracy: 0.7971 - val_loss: 1.3338 - val_accuracy: 0.6169\n",
            "Epoch 18/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5831 - accuracy: 0.7979 - val_loss: 1.3316 - val_accuracy: 0.6175\n",
            "Epoch 19/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5816 - accuracy: 0.7960 - val_loss: 1.3583 - val_accuracy: 0.6171\n",
            "Epoch 20/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5815 - accuracy: 0.7973 - val_loss: 1.3496 - val_accuracy: 0.6165\n",
            "Epoch 21/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5796 - accuracy: 0.7980 - val_loss: 1.3522 - val_accuracy: 0.6195\n",
            "Epoch 22/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5802 - accuracy: 0.7963 - val_loss: 1.3876 - val_accuracy: 0.6193\n",
            "Epoch 23/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5778 - accuracy: 0.7972 - val_loss: 1.3714 - val_accuracy: 0.6180\n",
            "Epoch 24/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.5799 - accuracy: 0.7978 - val_loss: 1.3528 - val_accuracy: 0.6180\n",
            "Epoch 25/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5775 - accuracy: 0.7992 - val_loss: 1.3717 - val_accuracy: 0.6175\n",
            "Epoch 26/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5792 - accuracy: 0.8003 - val_loss: 1.3675 - val_accuracy: 0.6178\n",
            "Epoch 27/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5775 - accuracy: 0.7970 - val_loss: 1.3296 - val_accuracy: 0.6174\n",
            "Epoch 28/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5776 - accuracy: 0.7986 - val_loss: 1.3596 - val_accuracy: 0.6191\n",
            "Epoch 29/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5781 - accuracy: 0.7991 - val_loss: 1.3456 - val_accuracy: 0.6159\n",
            "Epoch 30/30\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5759 - accuracy: 0.7986 - val_loss: 1.3789 - val_accuracy: 0.6168\n"
          ]
        }
      ]
    }
  ]
}